{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0da391c1-bca3-4c38-9d8d-d661c01087be",
   "metadata": {},
   "source": [
    "### Import The Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c57e1c33-5ccf-4a09-8bac-8d0dcf881f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - defaults/win-64::anaconda-catalogs==0.2.0=py311haa95532_0\n",
      "  - defaults/win-64::anaconda-navigator==2.5.0=py311haa95532_0\n",
      "  - defaults/win-64::astropy==5.3.4=py311hd7041d2_0\n",
      "  - defaults/win-64::black==23.11.0=py311haa95532_0\n",
      "  - defaults/noarch::bleach==4.1.0=pyhd3eb1b0_0\n",
      "  - defaults/win-64::bokeh==3.3.4=py311h746a85d_0\n",
      "  - defaults/win-64::conda==23.7.4=py311haa95532_0\n",
      "  - defaults/win-64::conda-build==3.26.1=py311haa95532_0\n",
      "  - defaults/noarch::conda-index==0.4.0=pyhd3eb1b0_0\n",
      "  - defaults/win-64::conda-libmamba-solver==23.7.0=py311haa95532_0\n",
      "  - defaults/noarch::conda-token==0.4.0=pyhd3eb1b0_0\n",
      "  - defaults/win-64::dask==2023.11.0=py311haa95532_0\n",
      "  - defaults/win-64::dask-core==2023.11.0=py311haa95532_0\n",
      "  - defaults/win-64::datasets==2.12.0=py311haa95532_0\n",
      "  - defaults/win-64::datashader==0.16.0=py311haa95532_0\n",
      "  - defaults/win-64::distributed==2023.11.0=py311haa95532_0\n",
      "  - defaults/win-64::holoviews==1.18.2=py311haa95532_0\n",
      "  - defaults/win-64::huggingface_hub==0.17.3=py311haa95532_0\n",
      "  - defaults/win-64::hvplot==0.9.2=py311haa95532_0\n",
      "  - defaults/win-64::intake==0.6.8=py311haa95532_0\n",
      "  - defaults/win-64::ipykernel==6.28.0=py311haa95532_0\n",
      "  - defaults/win-64::ipywidgets==8.0.4=py311haa95532_0\n",
      "  - defaults/win-64::jupyter==1.0.0=py311haa95532_8\n",
      "  - defaults/win-64::jupyter-lsp==2.2.0=py311haa95532_0\n",
      "  - defaults/win-64::jupyterlab==4.0.11=py311haa95532_0\n",
      "  - defaults/win-64::jupyterlab_server==2.25.1=py311haa95532_0\n",
      "  - defaults/win-64::jupyter_console==6.6.3=py311haa95532_0\n",
      "  - defaults/win-64::jupyter_server==2.10.0=py311haa95532_0\n",
      "  - defaults/win-64::matplotlib==3.8.0=py311haa95532_0\n",
      "  - defaults/win-64::matplotlib-base==3.8.0=py311hf62ec03_0\n",
      "  - defaults/win-64::navigator-updater==0.4.0=py311haa95532_1\n",
      "  - defaults/win-64::nbconvert==7.10.0=py311haa95532_0\n",
      "  - defaults/win-64::notebook==7.0.6=py311haa95532_0\n",
      "  - defaults/win-64::notebook-shim==0.2.3=py311haa95532_0\n",
      "  - defaults/win-64::numpydoc==1.5.0=py311haa95532_0\n",
      "  - defaults/win-64::panel==1.3.8=py311haa95532_0\n",
      "  - defaults/noarch::pyls-spyder==0.4.0=pyhd3eb1b0_0\n",
      "  - defaults/win-64::pyqt==5.15.10=py311hd77b12b_0\n",
      "  - defaults/win-64::pyqtwebengine==5.15.10=py311hd77b12b_0\n",
      "  - defaults/win-64::pytables==3.9.2=py311h91a9f6a_0\n",
      "  - defaults/win-64::pytest==7.4.0=py311haa95532_0\n",
      "  - defaults/win-64::python-lsp-black==1.2.1=py311haa95532_0\n",
      "  - defaults/win-64::python-lsp-server==1.7.2=py311haa95532_0\n",
      "  - defaults/win-64::pytoolconfig==1.2.6=py311haa95532_0\n",
      "  - defaults/win-64::qtawesome==1.2.2=py311haa95532_0\n",
      "  - defaults/win-64::qtconsole==5.4.2=py311haa95532_0\n",
      "  - defaults/win-64::qtpy==2.4.1=py311haa95532_0\n",
      "  - defaults/win-64::rope==1.7.0=py311haa95532_0\n",
      "  - defaults/win-64::scikit-image==0.22.0=py311hb4ba03d_0\n",
      "  - defaults/win-64::scrapy==2.8.0=py311haa95532_0\n",
      "  - defaults/win-64::seaborn==0.12.2=py311haa95532_0\n",
      "  - defaults/win-64::sip==6.7.12=py311hd77b12b_0\n",
      "  - defaults/win-64::sphinx==5.0.2=py311haa95532_0\n",
      "  - defaults/win-64::spyder==5.4.3=py311haa95532_1\n",
      "  - defaults/win-64::spyder-kernels==2.4.4=py311haa95532_0\n",
      "  - defaults/win-64::statsmodels==0.14.0=py311hd7041d2_0\n",
      "  - defaults/win-64::transformers==4.32.1=py311haa95532_0\n",
      "  - defaults/win-64::xarray==2023.6.0=py311haa95532_0\n",
      "  - defaults/win-64::_anaconda_depends==2023.09=py311_mkl_1\n",
      "\n",
      "CondaMemoryError: The conda process ran out of memory. Increase system memory and/or try again.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... unsuccessful initial attempt using frozen solve. Retrying with flexible solve.\n",
      "Solving environment: ...working... unsuccessful attempt using repodata from current_repodata.json, retrying with next repodata source.\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... unsuccessful initial attempt using frozen solve. Retrying with flexible solve.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'vaex'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 12\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# import logging\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# import random\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# from collections import Counter\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# import pandas as pd\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# %pip install vaex\u001b[39;00m\n\u001b[0;32m     11\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconda install -c conda-forge vaex\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mvaex\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'vaex'"
     ]
    }
   ],
   "source": [
    "# import logging\n",
    "# import random\n",
    "# from collections import Counter\n",
    "# from functools import partial\n",
    "# from pathlib import Path\n",
    "# from typing import Optional\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# %pip install vaex\n",
    "!conda install -c conda-forge vaex\n",
    "import vaex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da34a2fe-7d78-4ffe-95b0-4383c5a0efe7",
   "metadata": {},
   "source": [
    "### Define the directories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f47ba1-a114-4296-9414-3c07e2afe312",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = Path(\"E:/Paid projects/NLP_ICD10/Final Code/final_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a894554-e9e8-4974-b288-2291f971d103",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5532325-58c7-4ba2-b081-b7a4471a5c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gz_file_into_df(path: Path, dtype: Optional[dict] = None):\n",
    "    \"\"\"Reads the notes from a path into a dataframe. Saves the file as a feather file.\"\"\"\n",
    "    download_dir = path.parents[0]\n",
    "    stemmed_filename = path.name.split(\".\")[0]\n",
    "    if (download_dir / f\"{stemmed_filename}.feather\").is_file():\n",
    "        logging.info(\n",
    "            f\"{stemmed_filename}.feather already exists, loading data from {stemmed_filename}.feather into a pandas dataframe.\"\n",
    "        )\n",
    "        return pd.read_feather(download_dir / f\"{stemmed_filename}.feather\")\n",
    "\n",
    "    logging.info(\n",
    "        f\"Loading data from {stemmed_filename}.csv.gz into a pandas dataframe. This may take a while...\"\n",
    "    )\n",
    "    file = pd.read_csv(\n",
    "        download_dir / f\"{stemmed_filename}.csv.gz\", compression=\"gzip\", dtype=dtype\n",
    "    )\n",
    "    file.to_feather(download_dir / f\"{stemmed_filename}.feather\")\n",
    "\n",
    "    return file\n",
    "\n",
    "def reformat_icd(code: str, version: int, is_diag: bool) -> str:\n",
    "    \"\"\"format icd code depending on version\"\"\"\n",
    "    if version == 9:\n",
    "        return reformat_icd9(code, is_diag)\n",
    "    elif version == 10:\n",
    "        return reformat_icd10(code, is_diag)\n",
    "    else:\n",
    "        raise ValueError(\"version must be 9 or 10\")\n",
    "\n",
    "def reformat_icd10(code: str, is_diag: bool) -> str:\n",
    "    \"\"\"\n",
    "    Put a period in the right place because the MIMIC-3 data files exclude them.\n",
    "    Generally, procedure codes have dots after the first two digits,\n",
    "    while diagnosis codes have dots after the first three digits.\n",
    "    \"\"\"\n",
    "    code = \"\".join(code.split(\".\"))\n",
    "    if not is_diag:\n",
    "        return code\n",
    "    return code[:3] + \".\" + code[3:]\n",
    "\n",
    "def reformat_icd9(code: str, is_diag: bool) -> str:\n",
    "    \"\"\"\n",
    "    Put a period in the right place because the MIMIC-3 data files exclude them.\n",
    "    Generally, procedure codes have dots after the first two digits,\n",
    "    while diagnosis codes have dots after the first three digits.\n",
    "    \"\"\"\n",
    "    code = \"\".join(code.split(\".\"))\n",
    "    if is_diag:\n",
    "        if code.startswith(\"E\"):\n",
    "            if len(code) > 4:\n",
    "                return code[:4] + \".\" + code[4:]\n",
    "        else:\n",
    "            if len(code) > 3:\n",
    "                return code[:3] + \".\" + code[3:]\n",
    "    else:\n",
    "        if len(code) > 2:\n",
    "            return code[:2] + \".\" + code[2:]\n",
    "    return code\n",
    "\n",
    "def reformat_code_dataframe(row: pd.DataFrame, col: str) -> pd.Series:\n",
    "    return pd.Series({col: row[col].sort_values().tolist()})\n",
    "\n",
    "class TextPreprocessor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        lower: bool = True,\n",
    "        remove_special_characters_mullenbach: bool = True,\n",
    "        remove_special_characters: bool = False,\n",
    "        remove_digits: bool = True,\n",
    "        remove_accents: bool = False,\n",
    "        remove_brackets: bool = False,\n",
    "        convert_danish_characters: bool = False,\n",
    "    ) -> None:\n",
    "        self.lower = lower\n",
    "        self.remove_special_characters_mullenbach = remove_special_characters_mullenbach\n",
    "        self.remove_digits = remove_digits\n",
    "        self.remove_accents = remove_accents\n",
    "        self.remove_special_characters = remove_special_characters\n",
    "        self.remove_brackets = remove_brackets\n",
    "        self.convert_danish_characters = convert_danish_characters\n",
    "\n",
    "    def __call__(self, df: vaex.dataframe.DataFrame) -> vaex.dataframe.DataFrame:\n",
    "        if self.lower:\n",
    "            df[TEXT_COLUMN] = df[TEXT_COLUMN].str.lower()\n",
    "        if self.convert_danish_characters:\n",
    "            df[TEXT_COLUMN] = df[TEXT_COLUMN].str.replace(\"å\", \"aa\", regex=True)\n",
    "            df[TEXT_COLUMN] = df[TEXT_COLUMN].str.replace(\"æ\", \"ae\", regex=True)\n",
    "            df[TEXT_COLUMN] = df[TEXT_COLUMN].str.replace(\"ø\", \"oe\", regex=True)\n",
    "        if self.remove_accents:\n",
    "            df[TEXT_COLUMN] = df[TEXT_COLUMN].str.replace(\"é|è|ê\", \"e\", regex=True)\n",
    "            df[TEXT_COLUMN] = df[TEXT_COLUMN].str.replace(\"á|à|â\", \"a\", regex=True)\n",
    "            df[TEXT_COLUMN] = df[TEXT_COLUMN].str.replace(\"ô|ó|ò\", \"o\", regex=True)\n",
    "        if self.remove_brackets:\n",
    "            df[TEXT_COLUMN] = df[TEXT_COLUMN].str.replace(\"\\[[^]]*\\]\", \"\", regex=True)\n",
    "        if self.remove_special_characters:\n",
    "            df[TEXT_COLUMN] = df[TEXT_COLUMN].str.replace(\"\\n|/|-\", \" \", regex=True)\n",
    "            df[TEXT_COLUMN] = df[TEXT_COLUMN].str.replace(\n",
    "                \"[^a-zA-Z0-9 ]\", \"\", regex=True\n",
    "            )\n",
    "        if self.remove_special_characters_mullenbach:\n",
    "            df[TEXT_COLUMN] = df[TEXT_COLUMN].str.replace(\n",
    "                \"[^A-Za-z0-9]+\", \" \", regex=True\n",
    "            )\n",
    "        if self.remove_digits:\n",
    "            df[TEXT_COLUMN] = df[TEXT_COLUMN].str.replace(\"(\\s\\d+)+\\s\", \" \", regex=True)\n",
    "\n",
    "        df[TEXT_COLUMN] = df[TEXT_COLUMN].str.replace(\"\\s+\", \" \", regex=True)\n",
    "        df[TEXT_COLUMN] = df[TEXT_COLUMN].str.strip()\n",
    "        return df\n",
    "\n",
    "def preprocess_documents(\n",
    "    df: pd.DataFrame, preprocessor: TextPreprocessor\n",
    ") -> pd.DataFrame:\n",
    "    with vaex.cache.memory_infinite():  # pylint: disable=not-context-manager\n",
    "        df = vaex.from_pandas(df)\n",
    "        df = preprocessor(df)\n",
    "        df[\"num_words\"] = df.text.str.count(\" \") + 1\n",
    "        df[\"num_targets\"] = df[TARGET_COLUMN].apply(len)\n",
    "        return df.to_pandas_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c86f2a1-d1fc-422a-b1f6-ebd8496a912d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_codes(df: pd.DataFrame, columns: list[str], min_count: int) -> pd.DataFrame:\n",
    "    \"\"\"Filter the codes dataframe to only include codes that appear at least min_count times\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The codes dataframe\n",
    "        col (str): The column name of the codes\n",
    "        min_count (int): The minimum number of times a code must appear\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The filtered codes dataframe\n",
    "    \"\"\"\n",
    "    for col in columns:\n",
    "        code_counts = Counter([code for codes in df[col] for code in codes])\n",
    "        codes_to_keep = set(\n",
    "            code for code, count in code_counts.items() if count >= min_count\n",
    "        )\n",
    "        df[col] = df[col].apply(lambda x: [code for code in x if code in codes_to_keep])\n",
    "        print(f\"Number of unique codes in {col} before filtering: {len(code_counts)}\")\n",
    "        print(f\"Number of unique codes in {col} after filtering: {len(codes_to_keep)}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def parse_codes_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Parse the codes dataframe\"\"\"\n",
    "    df = df.rename(columns={\"hadm_id\": ID_COLUMN, \"subject_id\": SUBJECT_ID_COLUMN})\n",
    "    df = df.dropna(subset=[\"icd_code\"])\n",
    "    df = df.drop_duplicates(subset=[ID_COLUMN, \"icd_code\"])\n",
    "    df = (\n",
    "        df.groupby([SUBJECT_ID_COLUMN, ID_COLUMN, \"icd_version\"])\n",
    "        .apply(partial(reformat_code_dataframe, col=\"icd_code\"))\n",
    "        .reset_index()\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def parse_notes_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Parse the notes dataframe\"\"\"\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "            \"hadm_id\": ID_COLUMN,\n",
    "            \"subject_id\": SUBJECT_ID_COLUMN,\n",
    "            \"text\": TEXT_COLUMN,\n",
    "        }\n",
    "    )\n",
    "    df = df.dropna(subset=[TEXT_COLUMN])\n",
    "    df = df.drop_duplicates(subset=[ID_COLUMN, TEXT_COLUMN])\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41420a28-8b0a-4d9e-a92d-bda4bba3943f",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3866a39-8dc2-428a-b720-6c38237d959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_notes = load_gz_file_into_df(parent_dir / \"note/discharge.csv.gz\")\n",
    "mimic_proc = load_gz_file_into_df(parent_dir / \"hosp/procedures_icd.csv.gz\", dtype={\"icd_code\": str})\n",
    "mimic_diag = load_gz_file_into_df(parent_dir / \"hosp/diagnoses_icd.csv.gz\", dtype={\"icd_code\": str})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09806452-67bc-4b3e-bb7c-4496acda1233",
   "metadata": {},
   "source": [
    "### Format the codes by adding decimal points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a2df19-9f3f-4007-96fe-8e28b83991c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_proc[\"icd_code\"] = mimic_proc.apply(\n",
    "    lambda row: reformat_icd(\n",
    "        code=row[\"icd_code\"], version=row[\"icd_version\"], is_diag=False\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "mimic_diag[\"icd_code\"] = mimic_diag.apply(\n",
    "    lambda row: reformat_icd(\n",
    "        code=row[\"icd_code\"], version=row[\"icd_version\"], is_diag=True\n",
    "    ),\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ecd5dc-b8a4-4ca5-a55d-f40e383d7aa2",
   "metadata": {},
   "source": [
    "### Process codes and notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516a9ac6-8546-4ff7-b926-b83486f6fd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column names\n",
    "ID_COLUMN = \"_id\"\n",
    "TEXT_COLUMN = \"text\"\n",
    "TARGET_COLUMN = \"target\"\n",
    "SUBJECT_ID_COLUMN = \"subject_id\"\n",
    "\n",
    "# Process\n",
    "mimic_proc = parse_codes_dataframe(mimic_proc)\n",
    "mimic_diag = parse_codes_dataframe(mimic_diag)\n",
    "mimic_notes = parse_notes_dataframe(mimic_notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24258fe3-04c1-47df-b9f1-fdf35a74370d",
   "metadata": {},
   "source": [
    "### Merge the codes and notes into a icd9 and icd10 dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a2b5d3-393e-4c4c-8a7b-7e9f339ece08",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_TARGET_COUNT = 10  # Minimum number of times a code must appear to be included\n",
    "preprocessor = TextPreprocessor(\n",
    "    lower=True,\n",
    "    remove_special_characters_mullenbach=True,\n",
    "    remove_special_characters=False,\n",
    "    remove_digits=True,\n",
    "    remove_accents=False,\n",
    "    remove_brackets=False,\n",
    "    convert_danish_characters=False,\n",
    ")\n",
    "\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4260494e-5868-48b1-90bf-c332d1bc43f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_proc_9 = mimic_proc[mimic_proc[\"icd_version\"] == 9]\n",
    "mimic_proc_9 = mimic_proc_9.rename(columns={\"icd_code\": \"icd9_proc\"})\n",
    "mimic_proc_10 = mimic_proc[mimic_proc[\"icd_version\"] == 10]\n",
    "mimic_proc_10 = mimic_proc_10.rename(columns={\"icd_code\": \"icd10_proc\"})\n",
    "\n",
    "mimic_diag_9 = mimic_diag[mimic_diag[\"icd_version\"] == 9]\n",
    "mimic_diag_9 = mimic_diag_9.rename(columns={\"icd_code\": \"icd9_diag\"})\n",
    "mimic_diag_10 = mimic_diag[mimic_diag[\"icd_version\"] == 10]\n",
    "mimic_diag_10 = mimic_diag_10.rename(columns={\"icd_code\": \"icd10_diag\"})\n",
    "\n",
    "mimiciv_9 = mimic_notes.merge(\n",
    "    mimic_proc_9[[ID_COLUMN, \"icd9_proc\"]], on=ID_COLUMN, how=\"left\"\n",
    ")\n",
    "mimiciv_9 = mimiciv_9.merge(\n",
    "    mimic_diag_9[[ID_COLUMN, \"icd9_diag\"]], on=ID_COLUMN, how=\"left\"\n",
    ")\n",
    "\n",
    "mimiciv_10 = mimic_notes.merge(\n",
    "    mimic_proc_10[[ID_COLUMN, \"icd10_proc\"]], on=ID_COLUMN, how=\"left\"\n",
    ")\n",
    "mimiciv_10 = mimiciv_10.merge(\n",
    "    mimic_diag_10[[ID_COLUMN, \"icd10_diag\"]], on=ID_COLUMN, how=\"left\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3cdb2b-d474-46e1-abfc-577630b7877c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove notes with no codes\n",
    "mimiciv_9 = mimiciv_9.dropna(subset=[\"icd9_proc\", \"icd9_diag\"], how=\"all\")\n",
    "mimiciv_10 = mimiciv_10.dropna(subset=[\"icd10_proc\", \"icd10_diag\"], how=\"all\")\n",
    "\n",
    "# convert NaNs to empty lists\n",
    "mimiciv_9[\"icd9_proc\"] = mimiciv_9[\"icd9_proc\"].apply(\n",
    "    lambda x: [] if x is np.nan else x\n",
    ")\n",
    "mimiciv_9[\"icd9_diag\"] = mimiciv_9[\"icd9_diag\"].apply(\n",
    "    lambda x: [] if x is np.nan else x\n",
    ")\n",
    "mimiciv_10[\"icd10_proc\"] = mimiciv_10[\"icd10_proc\"].apply(\n",
    "    lambda x: [] if x is np.nan else x\n",
    ")\n",
    "mimiciv_10[\"icd10_diag\"] = mimiciv_10[\"icd10_diag\"].apply(\n",
    "    lambda x: [] if x is np.nan else x\n",
    ")\n",
    "\n",
    "mimiciv_9 = filter_codes(mimiciv_9, [\"icd9_proc\", \"icd9_diag\"], MIN_TARGET_COUNT)\n",
    "mimiciv_10 = filter_codes(mimiciv_10, [\"icd10_proc\", \"icd10_diag\"], MIN_TARGET_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940ca5c5-f7c7-4968-8510-bd5fe68fd87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define target\n",
    "mimiciv_9[TARGET_COLUMN] = mimiciv_9[\"icd9_proc\"] + mimiciv_9[\"icd9_diag\"]\n",
    "mimiciv_10[TARGET_COLUMN] = mimiciv_10[\"icd10_proc\"] + mimiciv_10[\"icd10_diag\"]\n",
    "\n",
    "# remove empty target\n",
    "mimiciv_9 = mimiciv_9[mimiciv_9[TARGET_COLUMN].apply(lambda x: len(x) > 0)]\n",
    "mimiciv_10 = mimiciv_10[mimiciv_10[TARGET_COLUMN].apply(lambda x: len(x) > 0)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe018b6-752f-4706-aeff-b3a1ea818ded",
   "metadata": {},
   "source": [
    "### Text preprocess the notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ce4727-d562-4c16-9886-02c4a98c3317",
   "metadata": {},
   "outputs": [],
   "source": [
    "mimiciv_9 = preprocess_documents(df=mimiciv_9, preprocessor=preprocessor)\n",
    "mimiciv_10 = preprocess_documents(df=mimiciv_10, preprocessor=preprocessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ecc2ec-d3c6-419d-971b-642587f20c63",
   "metadata": {},
   "source": [
    "### Save files to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3f8364-ad44-47e6-99cf-2151463e46c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mimiciv_9.to_feather(parent_dir / \"mimiciv_icd9.feather\")\n",
    "mimiciv_10.to_feather(parent_dir / \"mimiciv_icd10.feather\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_icd10",
   "language": "python",
   "name": "nlp_icd10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
